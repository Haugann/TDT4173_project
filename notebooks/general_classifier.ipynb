{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.8.5 64-bit",
      "metadata": {
        "interpreter": {
          "hash": "082e9a3bcad0a290d0001e938aa60b99250c6c2ef33a923c00b70f9826caf4b7"
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "EgZY-cMKePWF"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "from tensorflow.python.framework.ops import Tensor\n",
        "\n",
        "from keras.callbacks import History\n",
        "from keras.callbacks import ModelCheckpoint, TensorBoard\n",
        "from keras.datasets import cifar10\n",
        "from keras.engine import training\n",
        "from keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D, Dropout, Activation, Average, Maximum\n",
        "from keras.losses import categorical_crossentropy\n",
        "from keras.models import Model, Input, Sequential\n",
        "from keras.optimizers import Adam, SGD\n",
        "from keras.utils import to_categorical\n",
        "from keras.layers.core import Flatten, Dense, Dropout\n",
        "from keras.layers.convolutional import Convolution2D, MaxPooling2D, ZeroPadding2D\n",
        "\n",
        "from typing import Tuple, List\n",
        "import glob\n",
        "import os"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EcgebbqSeQj0"
      },
      "source": [
        "(train_images, train_labels), (test_images, test_labels) = datasets.cifar10.load_data()\n",
        "train_images, test_images = train_images / 255.0, test_images / 255.0\n",
        "train_labels = to_categorical(train_labels, num_classes=10)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vdbO9jX7eTAA"
      },
      "source": [
        "def cifar10_cnn_model(model_input: Tensor, model_name: str) -> training.Model:\n",
        "    \n",
        "    x = Conv2D(96, kernel_size=(3, 3), activation='relu', padding = 'same')(model_input)\n",
        "    x = Conv2D(96, (3, 3), activation='relu', padding = 'same')(x)\n",
        "    x = Conv2D(96, (3, 3), activation='relu', padding = 'same')(x)\n",
        "    x = MaxPooling2D(pool_size=(3, 3), strides = 2)(x)\n",
        "    x = Conv2D(192, (3, 3), activation='relu', padding = 'same')(x)\n",
        "    x = Conv2D(192, (3, 3), activation='relu', padding = 'same')(x)\n",
        "    x = Conv2D(192, (3, 3), activation='relu', padding = 'same')(x)\n",
        "    x = MaxPooling2D(pool_size=(3, 3), strides = 2)(x)\n",
        "    x = Conv2D(192, (3, 3), activation='relu', padding = 'same')(x)\n",
        "    x = Conv2D(192, (1, 1), activation='relu')(x)\n",
        "    x = Conv2D(10, (1, 1))(x)\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    x = Activation(activation='softmax')(x)\n",
        "    \n",
        "    model = Model(model_input, x, name=model_name)\n",
        "    \n",
        "    return model\n",
        "\n",
        "def make_cnn_model(train_data: np.ndarray, model_name: str):\n",
        "\tinput_shape = train_data[0,:,:,:].shape # (32,32,3)\n",
        "\tmodel_input = Input(shape=input_shape)\n",
        "\n",
        "\treturn cifar10_cnn_model(model_input, model_name)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YqOaGLQTeWMa"
      },
      "source": [
        "NUM_EPOCHS = 15\n",
        "\n",
        "# Note: Requires 'weights' folder to exist in order to save weights\n",
        "\n",
        "def compile_and_train(model: training.Model, num_epochs: int, x_train: np.ndarray, y_train: np.ndarray) -> Tuple [History, str]: \n",
        "    \n",
        "    model.compile(loss=categorical_crossentropy, optimizer=Adam(), metrics=['acc']) \n",
        "    filepath = 'weights/' + model.name + '.{epoch:02d}-{loss:.2f}.hdf5'\n",
        "    checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=0, save_weights_only=True, save_best_only=True, mode='auto')\n",
        "    tensor_board = TensorBoard(log_dir='logs/', histogram_freq=0, batch_size=32)\n",
        "    history = model.fit(x=x_train, y=y_train, batch_size=32, \n",
        "                     epochs=num_epochs, verbose=1, callbacks=[checkpoint, tensor_board], validation_split=0.2)\n",
        "    weight_files = glob.glob(os.path.join(os.getcwd(), 'weights/*'))\n",
        "    weight_file = max(weight_files, key=os.path.getctime) # most recent file\n",
        "    return history, weight_file\n",
        "\n",
        "def evaluate_error(model: training.Model) -> np.float64:\n",
        "    pred = model.predict(test_images, batch_size = 32)\n",
        "    pred = np.argmax(pred, axis=1)\n",
        "    pred = np.expand_dims(pred, axis=1) # make same shape as y_test\n",
        "    error = np.sum(np.not_equal(pred, test_labels)) / test_labels.shape[0]   \n",
        " \n",
        "    return error"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "47TB8mtueZzo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "329b3cc8-a250-4814-c97f-a9fe374d812e"
      },
      "source": [
        "# Instantiate and display model \n",
        "general_classifier = make_cnn_model(train_images, 'General')\n",
        "general_classifier.summary()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"General\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninput_1 (InputLayer)         [(None, 32, 32, 3)]       0         \n_________________________________________________________________\nconv2d (Conv2D)              (None, 32, 32, 96)        2688      \n_________________________________________________________________\nconv2d_1 (Conv2D)            (None, 32, 32, 96)        83040     \n_________________________________________________________________\nconv2d_2 (Conv2D)            (None, 32, 32, 96)        83040     \n_________________________________________________________________\nmax_pooling2d (MaxPooling2D) (None, 15, 15, 96)        0         \n_________________________________________________________________\nconv2d_3 (Conv2D)            (None, 15, 15, 192)       166080    \n_________________________________________________________________\nconv2d_4 (Conv2D)            (None, 15, 15, 192)       331968    \n_________________________________________________________________\nconv2d_5 (Conv2D)            (None, 15, 15, 192)       331968    \n_________________________________________________________________\nmax_pooling2d_1 (MaxPooling2 (None, 7, 7, 192)         0         \n_________________________________________________________________\nconv2d_6 (Conv2D)            (None, 7, 7, 192)         331968    \n_________________________________________________________________\nconv2d_7 (Conv2D)            (None, 7, 7, 192)         37056     \n_________________________________________________________________\nconv2d_8 (Conv2D)            (None, 7, 7, 10)          1930      \n_________________________________________________________________\nglobal_average_pooling2d (Gl (None, 10)                0         \n_________________________________________________________________\nactivation (Activation)      (None, 10)                0         \n=================================================================\nTotal params: 1,369,738\nTrainable params: 1,369,738\nNon-trainable params: 0\n_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GpFcoU39anph"
      },
      "source": [
        "# Train model\n",
        "If you want to load pre-trained weights, skip to next cell"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i5Trla-UedoF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "994d6f47-cc9d-4e5a-a18b-a3ff69a14485"
      },
      "source": [
        "history_1, classifier_weights = compile_and_train(general_classifier, NUM_EPOCHS, train_images, train_labels)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:`batch_size` is no longer needed in the `TensorBoard` Callback and will be ignored in TensorFlow 2.0.\n",
            "Epoch 1/15\n",
            "   2/1250 [..............................] - ETA: 47s - loss: 2.3043 - acc: 0.0938WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0072s vs `on_train_batch_end` time: 0.0651s). Check your callbacks.\n",
            "1250/1250 [==============================] - 14s 11ms/step - loss: 1.7314 - acc: 0.3413 - val_loss: 1.4634 - val_acc: 0.4778\n",
            "Epoch 2/15\n",
            "1250/1250 [==============================] - 13s 11ms/step - loss: 1.2165 - acc: 0.5575 - val_loss: 1.0588 - val_acc: 0.6136\n",
            "Epoch 3/15\n",
            "1250/1250 [==============================] - 13s 11ms/step - loss: 0.9833 - acc: 0.6486 - val_loss: 0.8878 - val_acc: 0.6865\n",
            "Epoch 4/15\n",
            "1250/1250 [==============================] - 13s 11ms/step - loss: 0.8185 - acc: 0.7149 - val_loss: 0.7976 - val_acc: 0.7150\n",
            "Epoch 5/15\n",
            "1250/1250 [==============================] - 13s 11ms/step - loss: 0.7062 - acc: 0.7526 - val_loss: 0.7049 - val_acc: 0.7565\n",
            "Epoch 6/15\n",
            "1250/1250 [==============================] - 13s 11ms/step - loss: 0.6160 - acc: 0.7849 - val_loss: 0.7158 - val_acc: 0.7496\n",
            "Epoch 7/15\n",
            "1250/1250 [==============================] - 13s 11ms/step - loss: 0.5506 - acc: 0.8075 - val_loss: 0.6947 - val_acc: 0.7649\n",
            "Epoch 8/15\n",
            "1250/1250 [==============================] - 14s 11ms/step - loss: 0.4798 - acc: 0.8317 - val_loss: 0.6426 - val_acc: 0.7861\n",
            "Epoch 9/15\n",
            "1250/1250 [==============================] - 13s 11ms/step - loss: 0.4200 - acc: 0.8531 - val_loss: 0.6905 - val_acc: 0.7712\n",
            "Epoch 10/15\n",
            "1250/1250 [==============================] - 13s 11ms/step - loss: 0.3616 - acc: 0.8722 - val_loss: 0.7190 - val_acc: 0.7766\n",
            "Epoch 11/15\n",
            "1250/1250 [==============================] - 14s 11ms/step - loss: 0.3210 - acc: 0.8855 - val_loss: 0.7241 - val_acc: 0.7913\n",
            "Epoch 12/15\n",
            "1250/1250 [==============================] - 13s 11ms/step - loss: 0.2725 - acc: 0.9024 - val_loss: 0.7548 - val_acc: 0.7863\n",
            "Epoch 13/15\n",
            "1250/1250 [==============================] - 13s 11ms/step - loss: 0.2320 - acc: 0.9172 - val_loss: 0.8510 - val_acc: 0.7808\n",
            "Epoch 14/15\n",
            "1250/1250 [==============================] - 13s 11ms/step - loss: 0.2121 - acc: 0.9251 - val_loss: 0.8366 - val_acc: 0.7843\n",
            "Epoch 15/15\n",
            "1250/1250 [==============================] - 14s 11ms/step - loss: 0.1876 - acc: 0.9334 - val_loss: 0.8690 - val_acc: 0.7799\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "shXLscargw1n",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "outputId": "9dce36e4-f3a7-4bb2-ebcc-c94c3faaab69"
      },
      "source": [
        "# Display name of the best weight file\n",
        "classifier_weights"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/weights/Overall.15-0.19.hdf5'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L3TVOHbWWzKk"
      },
      "source": [
        "## Load model from weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W0mpiRfdWya2"
      },
      "source": [
        "WEIGHTS = os.path.join(os.getcwd(), '../weights/general', 'General.15-0.19.hdf5')\n",
        "model_input = Input(shape=train_images[0,:,:,:].shape) # (32,32,3)\n",
        "\n",
        "general_classifier = cifar10_cnn_model(model_input, 'general')\n",
        "general_classifier.load_weights(WEIGHTS)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WkpwYjqjYPug"
      },
      "source": [
        "## Evaluate error rate of the classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qsnlMoLlYTYr",
        "outputId": "92f5c6cb-02fd-4d24-de05-e812feb2a3b1"
      },
      "source": [
        "print(\"Error rate - General classifier: \", evaluate_error(general_classifier)*100,'%')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error rate - General classifier:  22.05 %\n"
          ]
        }
      ]
    }
  ]
}